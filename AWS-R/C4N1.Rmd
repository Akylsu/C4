---
title: 'C4'
output:
  html_document:
    df_print: paged
subtitle: CEU Cloud Computing Course
---


In this notebook we are going to cover : Web Scraping and Comprehend functionalities such as Sentiment, Translate.

If you want to learn more about text analysis using R make sure you get this book:
https://www.tidytextmining.com/


### Comprehend

```{r}
library(aws.comprehend)
```


```{r}
# simple language detection
detect_language("This is a test sentence in English")
```

```{r}
# how about some non-sarcastic sentiment?
detect_sentiment("I have never been happier. This is the best day ever.")
```

```{r}
#We can detect entities in a given text
txt <- c("Central European University provides education", "Gyorgy Soros is the founder.",
         "Orban Viktor is the prime minister", "Vienna is a city")
detect_entities(txt)
```

translate some text 
```{r}
library(aws.translate)
translate("Bonjour le monde!", from = "fr", to = "en")
translate("Guten Tag!", from = "de", to = "en")
translate("My name is Cagdas", from = 'en', to = 'de')
```


### Scraping

```{r}
#Loading the rvest package
library('rvest')
```

```{r}
#Specifying the url for desired website to be scrapped
url <- 'https://fivethirtyeight.com/features/the-16-races-still-too-close-to-call/'

#Reading the HTML code from the website
webpage <- read_html(url)
```

Using CSS selectors to scrap the text related to the news article
```{r}
#text_data_html <- html_nodes(webpage,'<<PUT THE CSS SELECTION HERE>>')
text_data_html <- html_nodes(webpage,'.__reader_view_article_wrap_8724363608561669__ , p:nth-child(7) , #framediv4+ p , p:nth-child(3)')
```

Converting to text
```{r}
text_data <- html_text(text_data_html)

#Let's have a look at the text we got
head(text_data)
```

There are still strange characters in our text like `\n\t\tAll  newsletters\n\t`

```{r}
#removing unwanted garbage
text_data <- gsub("[\r\n\t]", "", text_data)

text_data %>%
  
```




